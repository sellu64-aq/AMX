##############################################################################
# Script: Telegraf Diameter Status
# Description: dra monitoring with InfluxDB integration
# Usage: with Telegraf
# Generated by Ansible for {{ inventory_hostname }}
# Develop: K. Selvam Enoch (777)
##############################################################################

[global_tags]
  project = "{{ project }}"
  zone = "{{ zone }}"
  nodeIP = "{{ ansible_host }}"
  service = "dra"

[agent]
  debug = true
  quiet = false
  interval = "30s"
  flush_interval = "30s"
  logfile = "{{ telegraf_remote_path }}/telegraf/logs/{{ telegraf_name }}_telegraf.log"
  hostname = "{{ inventory_hostname }}"
  omit_hostname = false
  round_interval = true
  metric_batch_size = 1000
  metric_buffer_limit = 20000
  collection_jitter = "0s"
  flush_jitter = "0s"
  precision = "0s"
  logfile_rotation_interval = "12h"
  logfile_rotation_max_size = "100MB"
  logfile_rotation_max_archives = 5

####### Port Status for {{ inventory_hostname }} #######
{% for item in ports %}
[[inputs.net_response]]
  protocol = "tcp"
  address = "{{ item.ip }}:{{ item.port }}"
  name_override = "portResponsetime"
  tags = { linkName="{{ item.name }}", ip="{{ item.ip }}", port="{{ item.port }}", host="{{ inventory_hostname }}" }
{% endfor %}

############# Port Monitor #############
[[inputs.exec]]
  commands = ["{{ telegraf_remote_path }}/scripts/{{ telegraf_name }}_port_listen_monitor.sh"]
  timeout = "10s"
  data_format = "influx"
  name_override = "port_listen"

############# Port Monitor #############
[[inputs.exec]]
  commands = ["{{ telegraf_remote_path }}/scripts/{{ telegraf_name }}_port_conn_monitor.sh"]
  timeout = "10s"
  data_format = "influx"
  name_override = "link_count"

############## Ping Monitoring ################
[[inputs.ping]]
  {% set unique_ips = ports | map(attribute='ip') | unique %}
  urls = [{% for ip in unique_ips %}"{{ ip }}"{% if not loop.last %}, {% endif %}{% endfor %}]
  count = 2
  ping_interval = 3.0
  timeout = 2.0
  method = "exec"

##### App Metrics ###########
[[inputs.exec]]
  commands = ["{{ telegraf_remote_path }}/scripts/{{ telegraf_name }}_app_metrics.sh"]
  data_format = "influx"
  name_override = "app_metrics"
  interval = "1m"
  timeout = "50s"

####### DRA Request processtime script ########
[[inputs.exec]]
  commands = ["{{ telegraf_remote_path }}/scripts/{{ telegraf_name }}_REQprocessingTime.sh"]
  data_format = "influx"
  interval = "1m"
  timeout = "50s"

############# dra Queue ###########
[[inputs.exec]]
  commands = [
    "/bin/bash -c 'host=$(hostname | tr '[:lower:]' '[:upper:]'); cd /opt/Roamware/scripts/operations || exit 1; current=$(/opt/rwperl/bin/perl get-int.pl 127.0.0.1 16131 1.3.6.1.4.1.11150.84.4.1.2.0); capacity=$(/opt/rwperl/bin/perl get-int.pl 127.0.0.1 16131 1.3.6.1.4.1.11150.84.4.1.3.0); enQueue=$(/opt/rwperl/bin/perl get-int.pl 127.0.0.1 16131 1.3.6.1.4.1.11150.84.4.2.1.0); deQueue=$(/opt/rwperl/bin/perl get-int.pl 127.0.0.1 16131 1.3.6.1.4.1.11150.84.4.2.2.0); if [[ -n $current && -n $capacity && -n $enQueue && -n $deQueue ]]; then echo \"DraQueue,host=$host,queue=current value=$current\"; echo \"DraQueue,host=$host,queue=capacity value=$capacity\"; echo \"DraQueue,host=$host,queue=enQueue value=$enQueue\"; echo \"DraQueue,host=$host,queue=deQueue value=$deQueue\"; fi'"
  ]
  timeout = "5s"
  name_override = "DraQueue"
  data_format = "influx"
  interval = "60s"

########## Tails ################

[[inputs.tail]]
  files = ["/opt/Roamware/logs/dra/logs/dra.log"]
  initial_read_offset = "beginning"
  watch_method = "inotify"
  name_override = "dra_logs"
  data_format = "grok"
  grok_patterns = [
    '''%{DAY:day} %{MONTH:month} %{MONTHDAY:monthday}\|%{TIME:time}\|%{WORD:level}\|Rule Executor %{NUMBER:executor_id}\|%{NOTSPACE:session_id}:\s+%{GREEDYDATA:message}\|%{NOTSPACE:java_class}\|%{NOTSPACE:method}\|%{NUMBER:line_no}'''
  ]
  grok_custom_patterns = '''
    TIME \d{2}:\d{2}:\d{2}\.\d+
  '''
[[processors.converter]]
  namepass = ["dra_logs"]
  [processors.converter.fields]
    tag = ["java_class", "level", "method"]

########## Traps ########
[[inputs.tail]]
  files = [
  "/opt/Roamware/logs/dra/traps/Traps-DRA-*.csv",
    "/opt/Roamware/logs/csvprocessor/traps/csvp-alarms.txt",
    "/opt/Roamware/logs/diameternode/traps/sds-alarms.txt"
]
  name_override = "SNMP"
  data_format = "grok"
  watch_method = "inotify"
  initial_read_offset = "end"

  grok_patterns = [
    '''%{DATA:dra_timestamp},%{DATA:host},%{DATA:device},%{GREEDYDATA:kvdata}'''
  ]

[[processors.starlark]]
  namepass = ["SNMP"]
  source = '''
def apply(metric):
    raw_log = metric.fields["kvdata"]
    parts = raw_log.split(',')
    key_value_pairs = []

    for part in parts:
        if "=" in part:
            key, value = part.split("=", 1)
            key_value_pairs.append((key.strip(), value.strip()))

    oid_map = {
        "1.3.6.1.4.1.11150.1.3.10": "AlarmTime",
        "1.3.6.1.4.1.11150.1.3.1": "severity",
        "1.3.6.1.4.1.11150.1.3.2": "description",
        "1.3.6.1.4.1.11150.1.3.13": "ServiceName",
        "1.3.6.1.4.1.11150.1.3.14": "AlarmType",
        "1.3.6.1.4.1.11150.1.3.17": "ProbableCause",
        "1.3.6.1.4.1.11150.1.3.21": "NotificationId",
        "1.3.6.1.4.1.11150.1.3.23": "SequenceNumber",
        "1.3.6.1.4.1.11150.1.3.3": "MachineID",
        "1.3.6.1.4.1.11150.1.3.39": "ResourceName",
        "1.3.6.1.4.1.11150.1.3.27": "KPIName",
        "trap": "trap",
        "trapName": "trapName",
        "enterprise": "enterprise"
    }

    tag_fields = ["MachineID", "description", "severity", "trapName"]

    for key, value in key_value_pairs:
        field_name = oid_map.get(key, key)
        clean_value = value.replace(" ", "_").replace("\\t", "_")
        if field_name in tag_fields:
            metric.tags[field_name] = clean_value
        else:
            metric.fields[field_name] = clean_value

    return metric
'''

[[inputs.tail]]
  files = ["/opt/Roamware/logs/dra/SummaryTrace-DRA.csv"]
  initial_read_offset = "end"
  name_override = "DRAlogs_SummaryTrace"
  grok_patterns = ["%{CUSTOM_draSummaryLOG}"]
  grok_custom_patterns = '''
  CUSTOM_draTIMESTAMP %{MONTHDAY}-%{MONTHNUM}-%{YEAR} %{HOUR}:%{MINUTE}:%{SECOND},%{INT:millisecond}
  CUSTOM_draSummaryLOG %{CUSTOM_draTIMESTAMP:timestamp},%{DATA},%{DATA},%{DATA},%{DATA},%{DATA},%{DATA},%{DATA},%{DATA},%{DATA:Type},%{DATA:FlowName},%{DATA},%{DATA},%{DATA},%{DATA},%{DATA},%{DATA},%{DATA},%{DATA},%{DATA},%{DATA},%{DATA},%{DATA},%{DATA},%{DATA},%{DATA},%{DATA},%{DATA},%{DATA},%{DATA},%{DATA},%{DATA:ResultCode},%{DATA},%{DATA},%{DATA},%{DATA},%{DATA},%{DATA},%{DATA},%{DATA},%{DATA},%{DATA}
'''
  data_format = "grok"

[[processors.converter]]
  namepass = ["DRAlogs_SummaryTrace"]
  [processors.converter.fields]
    integer = ["millisecond"]
    tag = ["ResultCode","FlowName","Type"]


[[inputs.tail]]
  files = ["/opt/Roamware/logs/dra/kpi/KPILog-DRA-*.csv"]
  initial_read_offset = "end"
  name_override = "DRAlogs_KPI"
  grok_patterns = ["%{CUSTOM_KPI_LOG}"]
  grok_custom_patterns = '''
    CUSTOM_TIMESTAMP %{YEAR}-%{MONTHNUM}-%{MONTHDAY},%{TIME:time}
    CUSTOM_KPI_LOG %{CUSTOM_TIMESTAMP:timestamp},%{DATA:Instance},%{DATA:RecordType},%{DATA:ComponentType},%{DATA:KPItype},%{DATA:TotalRequestReceived},%{DATA:TotalRequestThatHaveFlowDefined},%{DATA:TotalRequestRejectedBasedOnFilters},%{DATA:TotalFilterBasedRejectionForDiameterRequest},%{DATA:TotalRequestSampled},%{DATA:MaxTimeSpentToServeRequest},%{DATA:MinTimeSpentToServeRequest},%{DATA},%{DATA},%{DATA:AverageTimeSpentToServeSampledRequest}
  '''
  data_format = "grok"
[[processors.filter]]
  namepass = ["DRAlogs_KPI"]
  tagpass = ["ComponentType:DRA"]
  tagdrop = ["path"]
[[processors.converter]]
  namepass = ["DRAlogs_KPI"]
  [processors.converter.fields]
    integer = ["TotalRequestReceived","TotalRequestThatHaveFlowDefined","TotalRequestRejectedBasedOnFilters","TotalFilterBasedRejectionForDiameterRequest","TotalRequestSampled","MaxTimeSpentToServeRequest","MinTimeSpentToServeRequest","AverageTimeSpentToServeSampledRequest"]
    tag = ["ComponentType","RecordType","KPItype"]


[[inputs.tail]]
  files = ["/opt/Roamware/logs/restart.log"]
  initial_read_offset = "end"
  name_override = "RestartLog"
  data_format = "grok"
  grok_patterns = ["%{DRA_LOG_LINE}"]

  grok_custom_patterns = '''
    DRA_LOG_LINE %{DRA_TIMESTAMP:timestamp} %{WORD:event_type} %{DRA_MESSAGE:message} \[%{WORD:application}\]
    DRA_TIMESTAMP %{DAY} %{MONTH} +%{MONTHDAY} %{TIME} %{YEAR}
    DRA_MESSAGE (?:/[^ ]+|[^ ]+ ?[^ ]*)
  '''

[[processors.converter]]
  namepass = ["RestartLog"]
  [processors.converter.fields]
    tag = ["event_type", "application"]
[[processors.regex]]
  namepass = ["RestartLog"]
  [[processors.regex.fields]]
    key = "timestamp"
    pattern = " "
    replacement = "_"
    result_key = "timestamp"


### OUTPUTS Pri #####
[[outputs.influxdb]]
  urls = ["http://{{ influx_Pri_IP }}:{{ influx_Pri_Port }}"]
  database = "{{ influx_priDB_name }}"
  retention_policy = "thirty_days"
  timeout = "5s"
  skip_database_creation = true
  namepass = ["link_count","port_listen","BSSbyPass","RestartLog","DraQueue","IPPort_Status","portResponsetime","ip_listener_status","ping","app_metrics"]

[[outputs.influxdb]]
  urls = ["http://{{ influx_Pri_IP }}:{{ influx_Pri_Port }}"]
  database = "{{ influx_priDB_name }}"
  retention_policy = "1hrRP"
  timeout = "5s"
  skip_database_creation = true
  namepass = ["dra_logs","DRAlogs_SummaryTrace","DRAlogs_KPI"]

[[outputs.influxdb]]
  urls = ["http://{{ influx_Pri_IP }}:{{ influx_Pri_Port }}"]
  database = "{{ influx_priDB_name }}"
  retention_policy = "one_day"
  timeout = "5s"
  skip_database_creation = true
  namepass = ["SNMP"]

### OUTPUTS Sec #####
[[outputs.influxdb]]
  urls = ["http://{{ influx_Sec_IP }}:{{ influx_Sec_Port }}"]
  database = "{{ influx_secDB_name }}"
  retention_policy = "thirty_days"
  timeout = "5s"
  skip_database_creation = true
  namepass = ["link_count","port_listen","BSSbyPass","RestartLog","DraQueue","IPPort_Status","portResponsetime","ip_listener_status","ping","app_metrics"]

[[outputs.influxdb]]
  urls = ["http://{{ influx_Sec_IP }}:{{ influx_Sec_Port }}"]
  database = "{{ influx_secDB_name }}"
  retention_policy = "1hrRP"
  timeout = "5s"
  skip_database_creation = true
  namepass = ["dra_logs","DRAlogs_SummaryTrace","DRAlogs_KPI"]

[[outputs.influxdb]]
  urls = ["http://{{ influx_Sec_IP }}:{{ influx_Sec_Port }}"]
  database = "{{ influx_secDB_name }}"
  retention_policy = "one_day"
  timeout = "5s"
  skip_database_creation = true
  namepass = ["SNMP"]
