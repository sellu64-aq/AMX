{
  "uid": "{{ alert_uid }}",
  "folderUID": "{{ folder_uid }}",
  "ruleGroup": "{{ rulegroup }}",
  "title": "Spark Total Batch Delay",
  "condition": "C",
  "data": [
    {
      "refId": "A",
      "relativeTimeRange": {"from": 900, "to": 0},
      "datasourceUid": "{{ datasourceUid }}",
      "model": {
        "datasource": {"type": "influxdb", "uid": "{{ datasourceUid }}"},
        "instant": true,
        "intervalMs": 1000,
        "maxDataPoints": 43200,
        "query": "SELECT mean(\"orchestrationstreamingapi_gmsa_streamingmetrics_streaming_lastcompletedbatch_totaldelay_value\") FROM \"Spark_OrchestrationStreamingAPI\" WHERE $timeFilter group by host, project,zone, time(1m) fill(0)",
        "rawQuery": true,
        "refId": "A",
        "resultFormat": "time_series"
      }
    },
    {
      "refId": "B",
      "relativeTimeRange": {"from": 0, "to": 0},
      "datasourceUid": "__expr__",
      "model": {
        "conditions": [
          {
            "evaluator": { "params": [0, 0], "type": "gt" },
            "operator": {"type": "and"},
            "query": {"params": []},
            "reducer": {"params": [], "type": "avg"},
            "type": "query"
          }
        ],
        "datasource": {
          "name": "Expression",
          "type": "__expr__",
          "uid" : "__expr__"
        },
        "expression": "A",
        "intervalMs": 1000,
        "maxDataPoints": 43200,
        "reducer": "last",
        "refId": "B",
        "type": "reduce"
      }
    },
    {
      "refId": "C",
      "relativeTimeRange": {"from": 0, "to": 0},
      "datasourceUid": "__expr__",
      "model": {
        "conditions": [
          {
            "evaluator": { "params": [20, 0], "type": "gt" },
            "operator": {"type": "and"},
            "query": {"params": []},
            "reducer": {"params": [], "type": "avg"},
            "type": "query"
          }
        ],
        "datasource": {
          "name": "Expression",
          "type": "__expr__",
          "uid" : "__expr__"
        },
        "expression": "B",
        "intervalMs": 1000,
        "maxDataPoints": 43200,
        "refId": "C",
        "type": "threshold"
      }
    }
  ],
  "noDataState": "OK",
  "execErrState": "Error",
  "annotations": {
    "description": "End-to-End time for last completed batch increased â€” backlog or resource starvation.\n\nOps actions\n\nCheck Spark executor logs & driver UI for errors.\nCheck scheduling/processing delay metrics (below) to isolate stage.\nIncrease parallelism / add executors if CPU bound.\nCheck Kafka / input sink health (consumer lag).\nIf sudden spike, roll back recent changes or restart affected job."
  },
  "labels": {
    "platform": "{{ project }}",
    "zone"    : "{{ zone }}",
    "severity": "CRITICAL",
    "type"    : "{{ (rulegroup | string).split('_')[0] }}"
  },
  "isPaused": false
}
