{
  "uid": "{{ alert_uid }}",
  "folderUID": "{{ folder_uid }}",
  "ruleGroup": "{{ rulegroup }}",
  "title": "Spark LiveListenerBus - CRITICAL Queue Size",
  "condition": "E",
  "data": [
    {
      "refId": "A",
      "relativeTimeRange": {"from": 900, "to": 0},
      "datasourceUid": "{{ datasourceUid }}",
      "model": {
        "datasource": {"type": "influxdb", "uid": "{{ datasourceUid }}"},
        "instant": true,
        "intervalMs": 1000,
        "maxDataPoints": 43200,
        "query": "SELECT mean(\"livelistenerbus_queue_appstatus_size_value\") \nFROM \"spark_livelistenerbus\" \nWHERE $timeFilter \nGROUP BY time(1m),project, zone, host, nodeIP fill(0)",
        "rawQuery": true,
        "refId": "A",
        "resultFormat": "time_series"
      }
    },
    {
      "refId": "B",
      "relativeTimeRange": {"from": 900, "to": 0},
      "datasourceUid": "{{ datasourceUid }}",
      "model": {
        "datasource": {"type": "influxdb", "uid": "{{ datasourceUid }}"},
        "hide": false,
        "query": "SELECT mean(\"livelistenerbus_queue_executormanagement_size_value\") \nFROM \"spark_livelistenerbus\" \nWHERE $timeFilter \nGROUP BY time(1m),project, zone, host, nodeIP fill(0)",
        "rawQuery": true,
        "refId": "B",
        "resultFormat": "time_series"
      }
    },
    {
      "refId": "C",
      "relativeTimeRange": {"from": 0, "to": 0},
      "datasourceUid": "__expr__",
      "model": {
        "conditions": [
          {
            "evaluator": { "params": [0, 0], "type": "gt" },
            "operator": {"type": "and"},
            "query": {"params": []},
            "reducer": {"params": [], "type": "avg"},
            "type": "query"
          }
        ],
        "datasource": {
          "name": "Expression",
          "type": "__expr__",
          "uid" : "__expr__"
        },
        "expression": "A",
        "hide": false,
        "reducer": "last",
        "refId": "C",
        "type": "reduce"
      }
    },
    {
      "refId": "D",
      "relativeTimeRange": {"from": 0, "to": 0},
      "datasourceUid": "__expr__",
      "model": {
        "conditions": [
          {
            "evaluator": { "params": [0, 0], "type": "gt" },
            "operator": {"type": "and"},
            "query": {"params": []},
            "reducer": {"params": [], "type": "avg"},
            "type": "query"
          }
        ],
        "datasource": {
          "name": "Expression",
          "type": "__expr__",
          "uid" : "__expr__"
        },
        "expression": "B",
        "hide": false,
        "reducer": "last",
        "refId": "D",
        "type": "reduce"
      }
    },
    {
      "refId": "E",
      "relativeTimeRange": {"from": 0, "to": 0},
      "datasourceUid": "__expr__",
      "model": {
        "conditions": [
          {
            "evaluator": { "params": [0, 0], "type": "gt" },
            "operator": {"type": "and"},
            "query": {"params": []},
            "reducer": {"params": [], "type": "avg"},
            "type": "query"
          }
        ],
        "datasource": {
          "name": "Expression",
          "type": "__expr__",
          "uid" : "__expr__"
        },
        "expression": "($C > 1000) || ($D > 1000)",
        "hide": false,
        "refId": "E",
        "type": "math"
      }
    }
  ],
  "noDataState": "OK",
  "execErrState": "Error",
  "annotations": {
    "description": "Description:\nEvent queue size has exceeded critical threshold (5000 events). High risk of \ndropped events and event processing backlog. Listeners cannot keep up with \nevent generation rate.\n\nAction to Take:\n1. IMMEDIATE: Monitor for dropped events (Alert 1)\n2. Check driver resource utilization (CPU, memory)\n3. Review recent job submissions - possible event storm\n4. Increase queue capacity immediately if approaching limit\n5. Consider reducing UI retention settings\n6. Review listener processing times for bottlenecks\n7. If persistent, scale driver resources vertically"
  },
  "labels": {
    "platform": "{{ project }}",
    "zone"    : "{{ zone }}",
    "severity": "CRITICAL",
    "type"    : "{{ (rulegroup | string).split('_')[0] }}"
  },
  "isPaused": false
}
